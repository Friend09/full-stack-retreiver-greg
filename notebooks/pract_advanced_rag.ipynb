{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Advanced Retrieval With LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:07<00:00,  6.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load docs\n",
    "loader = DirectoryLoader(\n",
    "    \"../data/PaulGrahamEssaysLarge\", glob=\"**/*.txt\", show_progress=True\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"July 2006I've discovered a handy test for figuring out what you're addicted\\n\\nto. Imagine you were going to spend the weekend at a friend's house\\n\\non a little island off the coast of Maine. There are no shops on\\n\\nthe island and you won't be able to leave while you're there. Also,\\n\\nyou've never been to this house before, so you can't assume it will\\n\\nhave more than any house might.What, besides clothes and toiletries, do you make a point of packing?\\n\\nThat's what you're addicted to. For example, if you find yourself\\n\\npacking a bottle of vodka (just in case), you may want to stop and\\n\\nthink about that.For me the list is four things: books, earplugs, a notebook, and a\\n\\npen.There are other things I might bring if I thought of it, like music,\\n\\nor tea, but I can live without them. I'm not so addicted to caffeine\\n\\nthat I wouldn't risk the house not having any tea, just for a\\n\\nweekend.Quiet is another matter. I realize it seems a bit eccentric to\\n\\ntake earplugs on a trip to an island off the coast of Maine. If\\n\\nanywhere should be quiet, that should. But what if the person in\\n\\nthe next room snored? What if there was a kid playing basketball?\\n\\n(Thump, thump, thump... thump.) Why risk it? Earplugs are small.Sometimes I can think with noise. If I already have momentum on\\n\\nsome project, I can work in noisy places. I can edit an essay or\\n\\ndebug code in an airport. But airports are not so bad: most of the\\n\\nnoise is whitish. I couldn't work with the sound of a sitcom coming\", metadata={'source': '../data/PaulGrahamEssaysLarge/island.txt'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split docs\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vamsi_mbmax/Library/CloudStorage/OneDrive-Personal/01_vam_PROJECTS/LEARNING/proj_AI/dev_proj_AI/pract-fullstackretriever-greg/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# delete vectordb and start clean\n",
    "if \"vectordb\" in globals():\n",
    "    vectordb.delete_collection()\n",
    "\n",
    "embedding = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "vectordb = Chroma.from_documents(documents=splits, embedding=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTI QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set logging\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vamsi_mbmax/Library/CloudStorage/OneDrive-Personal/01_vam_PROJECTS/LEARNING/proj_AI/dev_proj_AI/pract-fullstackretriever-greg/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. How does the author perceive the initial phases of a startup?', \"2. What are the author's thoughts on the early development of a startup?\", '3. What insights does the author offer regarding the beginning stages of a startup?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the retriever, get multi queries from original question\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0)\n",
    "\n",
    "# initiate the retiever to work with llm\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(), llm=llm\n",
    ")\n",
    "\n",
    "# query the retriever\n",
    "question = \"What is the authors view on the early stages of a startup?\"\n",
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)\n",
    "\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt template\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The author believes that releasing a minimal version of a startup early is important, as it allows for quick improvements based on user feedback. The author also emphasizes the importance of getting version 1 done fast and states that many startups fail because they are too slow to release their product.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke the llm to get the answer to the original question\n",
    "response = llm.invoke(\n",
    "    input=PROMPT.format_prompt(context=unique_docs, question=question)\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTEXTUAL COMPRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- extracts only the relevant topic from the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-4\")\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['page_content', 'metadata', 'type'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"July 2006I've discovered a handy test for figuring out what you're addicted\\n\\nto. Imagine you were going to spend the weekend at a friend's house\\n\\non a little island off the coast of Maine. There are no shops on\\n\\nthe island and you won't be able to leave while you're there. Also,\\n\\nyou've never been to this house before, so you can't assume it will\\n\\nhave more than any house might.What, besides clothes and toiletries, do you make a point of packing?\\n\\nThat's what you're addicted to. For example, if you find yourself\\n\\npacking a bottle of vodka (just in case), you may want to stop and\\n\\nthink about that.For me the list is four things: books, earplugs, a notebook, and a\\n\\npen.There are other things I might bring if I thought of it, like music,\\n\\nor tea, but I can live without them. I'm not so addicted to caffeine\\n\\nthat I wouldn't risk the house not having any tea, just for a\\n\\nweekend.Quiet is another matter. I realize it seems a bit eccentric to\\n\\ntake earplugs on a trip to an island off the coast of Maine. If\\n\\nanywhere should be quiet, that should. But what if the person in\\n\\nthe next room snored? What if there was a kid playing basketball?\\n\\n(Thump, thump, thump... thump.) Why risk it? Earplugs are small.Sometimes I can think with noise. If I already have momentum on\\n\\nsome project, I can work in noisy places. I can edit an essay or\\n\\ndebug code in an airport. But airports are not so bad: most of the\\n\\nnoise is whitish. I couldn't work with the sound of a sitcom coming\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vamsi_mbmax/Library/CloudStorage/OneDrive-Personal/01_vam_PROJECTS/LEARNING/proj_AI/dev_proj_AI/pract-fullstackretriever-greg/.venv/lib/python3.12/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='What if there was a kid playing basketball? (Thump, thump, thump... thump.) Why risk it? Earplugs are small.', metadata={'source': '../data/PaulGrahamEssaysLarge/island.txt'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressor.compress_documents(\n",
    "    documents=[splits[0]], query=\"what about basketball\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARENT DOCUMENT RETRIEVER (IMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create child docs\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore for child docs\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"return_full_documents\",\n",
    "    embedding_function=OpenAIEmbeddings(api_key=OPENAI_API_KEY),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store parent, child documents\n",
    "store = InMemoryStore()\n",
    "\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,  # child docs\n",
    "    docstore=store,  # parent docs\n",
    "    child_splitter=child_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs, ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"people there are rich, or expect to be when their options vest.\\n\\nOrdinary employees find it very hard to recommend an acquisition;\\n\\nit's just too annoying to see a bunch of twenty year olds get rich\\n\\nwhen you're still working for salary. Even if it's the right thing\\n\\nfor your company to do.The Solution(s)Bad as things look now, there is a way for VCs to save themselves.\", metadata={'doc_id': '0653ca14-e81b-4a73-abf9-bd7998a275c0', 'source': '../data/PaulGrahamEssaysLarge/vcsqueeze.txt'}),\n",
       " Document(page_content=\"the product is expensive to develop or sell, or simply because\\n\\nthey're wasteful.If you're paying attention, you'll be asking at this point not just\\n\\nhow to avoid the fatal pinch, but how to avoid being default dead.\\n\\nThat one is easy: don't hire too fast. Hiring too fast is by far\\n\\nthe biggest killer of startups that raise money.\", metadata={'doc_id': 'e5e4072b-9f03-4cab-a0cd-b6e91abfa9a1', 'source': '../data/PaulGrahamEssaysLarge/aord.txt'}),\n",
       " Document(page_content=\"[1]\\n\\nBut investors are so fickle that you can never\\n\\ndo more than start to count on them. Sometimes something about your\\n\\nbusiness will spook investors even if your growth is great. So no\\n\\nmatter how good your growth is, you can never safely treat fundraising\\n\\nas more than a plan A. You should always have a plan B as well: you\\n\\nshould know (as in write down) precisely what you'll need to do to\", metadata={'doc_id': 'e5e4072b-9f03-4cab-a0cd-b6e91abfa9a1', 'source': '../data/PaulGrahamEssaysLarge/aord.txt'}),\n",
       " Document(page_content=\"head that it does in mine. And if you set off the alarms sufficiently\\n\\nearly, you may be able to avoid the fatal pinch.It would be safe to be default dead if you could count on investors\\n\\nsaving you. As a rule their interest is a function of\\n\\ngrowth. If you have steep revenue growth, say over 5x a year, you\\n\\ncan start to count on investors being interested even if you're not\\n\\nprofitable.\\n\\n[1]\", metadata={'doc_id': 'e5e4072b-9f03-4cab-a0cd-b6e91abfa9a1', 'source': '../data/PaulGrahamEssaysLarge/aord.txt'})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# child docs vector store retriever\n",
    "sub_docs = vectorstore.similarity_search(\"what is some investing advice?\")\n",
    "sub_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"November 2005In the next few years, venture capital funds will find themselves\\n\\nsqueezed from four directions. They're already stuck with a seller's\\n\\nmarket, because of the huge amounts they raised at the end of the\\n\\nBubble and still haven't invested. This by itself is not the end\\n\\nof the world. In fact, it's just a more extreme version of the\\n\\nnorm\\n\\nin the VC business: too much money chasing too few deals.Unfortunately, those few deals now want less and less money, because\\n\\nit's getting so cheap to start a startup. The four causes: open\\n\\nsource, which makes software free; Moore's law, which makes hardware\\n\\ngeometrically closer to free; the Web, which makes promotion free\\n\\nif you're good; and better languages, which make development a lot\\n\\ncheaper.When we started our startup in 1995, the first three were our biggest\\n\\nexpenses. We had to pay $5000 for the Netscape Commerce Server,\\n\\nthe only software that then supported secure http connections. We\\n\\npaid $3000 for a server with a 90 MHz p\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the parent docs from combined retriever\n",
    "retrieved_docs = retriever.get_relevant_documents(\"what is some investing advice?\")\n",
    "retrieved_docs[0].page_content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"return_split_parent_documents\",\n",
    "    embedding_function=OpenAIEmbeddings(api_key=OPENAI_API_KEY),\n",
    ")\n",
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the full combined retriever\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(store.yield_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"people there are rich, or expect to be when their options vest.\\n\\nOrdinary employees find it very hard to recommend an acquisition;\\n\\nit's just too annoying to see a bunch of twenty year olds get rich\\n\\nwhen you're still working for salary. Even if it's the right thing\\n\\nfor your company to do.The Solution(s)Bad as things look now, there is a way for VCs to save themselves.\", metadata={'doc_id': 'a62bea98-3506-4e26-aa7c-68e8b09bcc41', 'source': '../data/PaulGrahamEssaysLarge/vcsqueeze.txt'}),\n",
       " Document(page_content=\"the product is expensive to develop or sell, or simply because\\n\\nthey're wasteful.If you're paying attention, you'll be asking at this point not just\\n\\nhow to avoid the fatal pinch, but how to avoid being default dead.\\n\\nThat one is easy: don't hire too fast. Hiring too fast is by far\\n\\nthe biggest killer of startups that raise money.\", metadata={'doc_id': 'a7a06dc2-d468-4841-829b-1a2d2a26783f', 'source': '../data/PaulGrahamEssaysLarge/aord.txt'}),\n",
       " Document(page_content=\"[1]\\n\\nBut investors are so fickle that you can never\\n\\ndo more than start to count on them. Sometimes something about your\\n\\nbusiness will spook investors even if your growth is great. So no\\n\\nmatter how good your growth is, you can never safely treat fundraising\\n\\nas more than a plan A. You should always have a plan B as well: you\\n\\nshould know (as in write down) precisely what you'll need to do to\", metadata={'doc_id': '4dff7e2b-c201-4fb9-90c4-bf9ece6b2da0', 'source': '../data/PaulGrahamEssaysLarge/aord.txt'}),\n",
       " Document(page_content=\"head that it does in mine. And if you set off the alarms sufficiently\\n\\nearly, you may be able to avoid the fatal pinch.It would be safe to be default dead if you could count on investors\\n\\nsaving you. As a rule their interest is a function of\\n\\ngrowth. If you have steep revenue growth, say over 5x a year, you\\n\\ncan start to count on investors being interested even if you're not\\n\\nprofitable.\\n\\n[1]\", metadata={'doc_id': '4dff7e2b-c201-4fb9-90c4-bf9ece6b2da0', 'source': '../data/PaulGrahamEssaysLarge/aord.txt'})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here similarity search performs the search on the child chunks\n",
    "sub_docs = vectorstore.similarity_search(\"what is some investing advice?\")\n",
    "sub_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='all practical purposes, succeeding now equals getting bought. Which\\n\\nmeans VCs are now in the business of finding promising little 2-3\\n\\nman startups and pumping them up into companies that cost $100\\n\\nmillion to acquire. They didn\\'t mean to be in this business; it\\'s\\n\\njust what their business has evolved into.Hence the fourth problem: the acquirers have begun to realize they\\n\\ncan buy wholesale. Why should they wait for VCs to make the startups\\n\\nthey want more expensive? Most of what the VCs add, acquirers don\\'t\\n\\nwant anyway. The acquirers already have brand recognition and HR\\n\\ndepartments. What they really want is the software and the developers,\\n\\nand that\\'s what the startup is in the early phase: concentrated\\n\\nsoftware and developers.Google, typically, seems to have been the first to figure this out.\\n\\n\"Bring us your startups early,\" said Google\\'s speaker at the Startup School. They\\'re quite\\n\\nexplicit about it: they like to acquire startups at just the point\\n\\nwhere they would do a Series A round. (The Series A round is the\\n\\nfirst round of real VC funding; it usually happens in the first\\n\\nyear.) It is a brilliant strategy, and one that other big technology\\n\\ncompanies will no doubt try to duplicate. Unless they want to have\\n\\nstill more of their lunch eaten by Google.Of course, Google has an advantage in buying startups: a lot of the\\n\\npeople there are rich, or expect to be when their options vest.\\n\\nOrdinary employees find it very hard to recommend an acquisition;\\n\\nit\\'s just too annoying to see a bunch of twenty year olds get rich\\n\\nwhen you\\'re still working for salary. Even if it\\'s the right thing\\n\\nfor your company to do.The Solution(s)Bad as things look now, there is a way for VCs to save themselves.\\n\\nThey need to do two things, one of which won\\'t surprise them, and\\n\\nanother that will seem an anathema.Let\\'s start with the obvious one: lobby to get Sarbanes-Oxley\\n\\nloosened. This law was created to prevent future Enrons, not to', metadata={'source': '../data/PaulGrahamEssaysLarge/vcsqueeze.txt'})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here the retriever after performing the search on child chunks, gets the parent docs\n",
    "larger_chunk_relevant_docs = retriever.get_relevant_documents(\n",
    "    \"what is some investing advice?\"\n",
    ")\n",
    "larger_chunk_relevant_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "question = \"what is some investing advice?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One piece of investing advice is for venture capitalists to not overinflate the value of startups they invest in. This is because acquirers have begun to realize they can buy wholesale and do not need to wait for VCs to make the startups they want more expensive. Another piece of advice is for startups to not hire too fast as this is often the biggest killer of startups that raise money. They should focus on making their product more appealing to boost growth. Lastly, startups should always have a plan B in case they can't raise more money.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\n",
    "    input=PROMPT.format_prompt(\n",
    "        context=larger_chunk_relevant_docs, question=question)\n",
    ").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSEMBLE RETRIEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the bm25 - keyword matching retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "bm25_retriever.k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main document retriever\n",
    "embedding = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "vectordb = Chroma.from_documents(splits, embedding)\n",
    "vectordb = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the retreivers\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vectordb], weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "ensemble_docs = ensemble_retriever.get_relevant_documents(\n",
    "    \"what is some investing advice?\"\n",
    ")\n",
    "\n",
    "len(ensemble_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One piece of investing advice is to make a larger number of smaller investments instead of a few large ones. It's also suggested to fund younger, more technical founders instead of MBAs and to let the founders remain as CEOs. Another advice is that the best sources of seed funding are successful startup founders because they can also provide advice. However, it's important to be aware that high valuations startups are getting may not last forever and that there's a risk in having VCs in an angel round.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "question = \"what is some investing advice?\"\n",
    "\n",
    "llm.invoke(input=PROMPT.format_prompt(\n",
    "    context=ensemble_docs, question=question)).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELF QUERYING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete existing vector store\n",
    "if (\n",
    "    \"vectorstore\" in globals()\n",
    "):  # If you've already made your vectordb this will delete it so you start fresh\n",
    "    vectorstore.delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(splits, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The filename of the essay\",\n",
    "        type=\"string or list[string]\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Essays from Paul Graham\"\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True,\n",
    "    enable_limit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"July 2006I've discovered a handy test for figuring out what you're addicted\\n\\nto. Imagine you were going to spend the weekend at a friend's house\\n\\non a little island off the coast of Maine. There are no shops on\\n\\nthe island and you won't be able to leave while you're there. Also,\\n\\nyou've never been to this house before, so you can't assume it will\\n\\nhave more than any house might.What, besides clothes and toiletries, do you make a point of packing?\\n\\nThat's what you're addicted to. For example, if you find yourself\\n\\npacking a bottle of vodka (just in case), you may want to stop and\\n\\nthink about that.For me the list is four things: books, earplugs, a notebook, and a\\n\\npen.There are other things I might bring if I thought of it, like music,\\n\\nor tea, but I can live without them. I'm not so addicted to caffeine\\n\\nthat I wouldn't risk the house not having any tea, just for a\\n\\nweekend.Quiet is another matter. I realize it seems a bit eccentric to\\n\\ntake earplugs on a trip to an island off the coast of Maine. If\\n\\nanywhere should be quiet, that should. But what if the person in\\n\\nthe next room snored? What if there was a kid playing basketball?\\n\\n(Thump, thump, thump... thump.) Why risk it? Earplugs are small.Sometimes I can think with noise. If I already have momentum on\\n\\nsome project, I can work in noisy places. I can edit an essay or\\n\\ndebug code in an airport. But airports are not so bad: most of the\\n\\nnoise is whitish. I couldn't work with the sound of a sitcom coming\", metadata={'source': '../data/PaulGrahamEssaysLarge/island.txt'})]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\n",
    "    \"Return only 1 essay. What is one thing you can do to figure out what you like to do from source '../data/PaulGrahamEssaysLarge/island.txt'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/PaulGrahamEssaysLarge/island.txt'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the url\n",
    "import re\n",
    "\n",
    "for split in splits:\n",
    "    split.metadata[\"essay\"] = re.search(\n",
    "        r\"[^/]+(?=\\.\\w+$)\", split.metadata[\"source\"]\n",
    "    ).group()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '../data/PaulGrahamEssaysLarge/gh.txt', 'essay': 'gh'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"essay\", description=\"The name of the essay\", type=\"string or list[string]\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    \"vectorstore\" in globals()\n",
    "):  # If you've already made your vectordb this will delete it so you start fresh\n",
    "    vectorstore.delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(splits, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Essays from Paul Graham\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True,\n",
    "    enable_limit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='should make a larger number of smaller investments instead of a\\n\\nhandful of giant ones, they should be funding younger, more technical\\n\\nfounders instead of MBAs, they should let the founders remain as\\n\\nCEO, and so on.One of my tricks for writing essays had always been to give talks.\\n\\nThe prospect of having to stand up in front of a group of people\\n\\nand tell them something that won\\'t waste their time is a great\\n\\nspur to the imagination. When the Harvard Computer Society, the\\n\\nundergrad computer club, asked me to give a talk, I decided I would\\n\\ntell them how to start a startup. Maybe they\\'d be able to avoid the\\n\\nworst of the mistakes we\\'d made.So I gave this talk, in the course of which I told them that the\\n\\nbest sources of seed funding were successful startup founders,\\n\\nbecause then they\\'d be sources of advice too. Whereupon it seemed\\n\\nthey were all looking expectantly at me. Horrified at the prospect\\n\\nof having my inbox flooded by business plans (if I\\'d only known),\\n\\nI blurted out \"But not me!\" and went on with the talk. But afterward\\n\\nit occurred to me that I should really stop procrastinating about\\n\\nangel investing. I\\'d been meaning to since Yahoo bought us, and now\\n\\nit was 7 years later and I still hadn\\'t done one angel investment.Meanwhile I had been scheming with Robert and Trevor about projects\\n\\nwe could work on together. I missed working with them, and it seemed', metadata={'essay': 'worked', 'source': '../data/PaulGrahamEssaysLarge/worked.txt'})]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\n",
    "    \"Tell me about investment advice the 'worked' essay? return only 1\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
